name: Cold Email Sync

# Automated pipeline to sync leads from BigQuery to Instantly.ai

on:
  schedule:
    # Run every hour during extended business hours (3 AM - 9 PM EST, Mon-Fri)
    - cron: '0 7-23,0-1 * * 1-5'  # UTC times for EST business hours (3am-9pm EST = 7am-1am UTC)
    # Run every 2 hours on weekends
    - cron: '0 */2 * * 0,6'  # Weekends
  workflow_dispatch:  # Allow manual triggers
    inputs:
      dry_run:
        description: 'Run in dry mode (no actual changes)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
      target_leads:
        description: 'Number of new leads to process'
        required: false
        default: '10'

permissions:
  contents: read

jobs:
  sync:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Create initial log file
        run: |
          echo "GitHub Actions workflow started at $(date)" > workflow.log
          echo "Runner: ${{ runner.os }}" >> workflow.log
          echo "GitHub ref: ${{ github.ref }}" >> workflow.log
          ls -la >> workflow.log 2>&1
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          echo "üì¶ Installing dependencies..." | tee -a workflow.log
          pip install --upgrade pip 2>&1 | tee -a workflow.log
          
          # Install from requirements.txt to ensure all dependencies are included
          if [ -f requirements.txt ]; then
            echo "üì¶ Installing from requirements.txt..." | tee -a workflow.log
            pip install -r requirements.txt 2>&1 | tee -a workflow.log
          else
            echo "‚ö†Ô∏è requirements.txt not found, installing minimal dependencies..." | tee -a workflow.log
            pip install google-cloud-bigquery requests tenacity 2>&1 | tee -a workflow.log
          fi
          
          echo "‚úÖ Dependencies installed" | tee -a workflow.log
      
      - name: Create credentials file
        env:
          BIGQUERY_CREDS: ${{ secrets.BIGQUERY_CREDENTIALS_JSON }}
          INSTANTLY_KEY: ${{ secrets.INSTANTLY_API_KEY }}
        run: |
          echo "üìÅ Creating directory structure..." | tee -a workflow.log
          mkdir -p config/secrets
          
          # Debug: Check if secrets are available (without exposing them)
          echo "üîç Checking secrets availability..." | tee -a workflow.log
          
          # Check BigQuery credentials
          if [ -z "${BIGQUERY_CREDS}" ]; then
            echo "‚ùå ERROR: BIGQUERY_CREDENTIALS_JSON secret not set" | tee -a workflow.log
            exit 1
          else
            echo "‚úÖ BIGQUERY_CREDENTIALS_JSON secret is available (${#BIGQUERY_CREDS} chars)" | tee -a workflow.log
          fi
          
          # Check Instantly API key
          if [ -z "${INSTANTLY_KEY}" ]; then
            echo "‚ùå ERROR: INSTANTLY_API_KEY secret not set" | tee -a workflow.log
            exit 1
          else
            echo "‚úÖ INSTANTLY_API_KEY secret is available" | tee -a workflow.log
          fi
          
          # Create credentials file using environment variable
          echo "üìù Creating credentials file..." | tee -a workflow.log
          # Use printf to properly handle escaped characters in JSON
          printf '%s' "${BIGQUERY_CREDS}" > config/secrets/bigquery-credentials.json
          chmod 600 config/secrets/bigquery-credentials.json
          
          # Verify file was created
          if [ -f "config/secrets/bigquery-credentials.json" ]; then
            file_size=$(stat -c%s "config/secrets/bigquery-credentials.json" 2>/dev/null || stat -f%z "config/secrets/bigquery-credentials.json" 2>/dev/null || echo "unknown")
            echo "‚úÖ Credentials file created successfully ($file_size bytes)" | tee -a workflow.log
            
            # Validate JSON format
            if python -m json.tool config/secrets/bigquery-credentials.json > /dev/null 2>&1; then
              echo "‚úÖ Credentials file is valid JSON" | tee -a workflow.log
              
              # Credentials file is valid, ready to proceed
            else
              echo "‚ùå ERROR: Credentials file is not valid JSON" | tee -a workflow.log
              echo "First 200 chars of file:" | tee -a workflow.log
              head -c 200 config/secrets/bigquery-credentials.json | tee -a workflow.log
              echo "" | tee -a workflow.log
              echo "JSON validation error:" | tee -a workflow.log
              python -m json.tool config/secrets/bigquery-credentials.json 2>&1 | tee -a workflow.log
              exit 1
            fi
          else
            echo "‚ùå ERROR: Failed to create credentials file" | tee -a workflow.log
            exit 1
          fi
      
      - name: Debug Python environment
        run: |
          echo "üêç Python version:"
          python --version
          echo ""
          echo "üì¶ Installed packages:"
          pip list
          echo ""
          echo "üìÅ Current directory contents:"
          ls -la
          echo ""
          echo "üìÇ Config directory:"
          ls -la config/secrets/ || echo "config/secrets not found"
          
      - name: Validate environment
        env:
          INSTANTLY_API_KEY: ${{ secrets.INSTANTLY_API_KEY }}
        run: |
          echo "üîç Validating GitHub Actions environment..."
          python validate_environment.py || {
            echo "‚ùå Environment validation failed with exit code $?"
            exit 1
          }
          
      - name: Test imports
        run: |
          echo "üß™ Testing Python imports..."
          python -c "import os; print('‚úÖ os module OK')"
          python -c "import logging; print('‚úÖ logging module OK')"
          python -c "from google.cloud import bigquery; print('‚úÖ google.cloud.bigquery OK')" || echo "‚ùå Failed to import bigquery"
          python -c "import requests; print('‚úÖ requests OK')" || echo "‚ùå Failed to import requests"
          python -c "import tenacity; print('‚úÖ tenacity OK')" || echo "‚ùå Failed to import tenacity"
          
          
      - name: Run sync
        env:
          # Required secrets
          INSTANTLY_API_KEY: ${{ secrets.INSTANTLY_API_KEY }}
          
          # Configuration
          TARGET_NEW_LEADS_PER_RUN: ${{ github.event.inputs.target_leads || '50' }}
          INSTANTLY_CAP_GUARD: '24000'
          BATCH_SIZE: '50'  # Conservative for startup
          BATCH_SLEEP_SECONDS: '10'
          LEAD_INVENTORY_MULTIPLIER: '10'  # Increased from 3.5 to allow testing with higher inventory
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
          SKIP_SYNC_VERIFICATION: 'false'  # Enable marking leads for verification
          
          # Notification settings
          SLACK_NOTIFICATION_CHANNEL: ${{ secrets.SLACK_NOTIFICATION_CHANNEL }}
          SLACK_NOTIFICATIONS_ENABLED: ${{ secrets.SLACK_NOTIFICATIONS_ENABLED }}
          
          # Python path
          PYTHONPATH: .
        
        run: |
          echo "üöÄ Starting Cold Email Sync" | tee -a workflow.log
          echo "Target leads: $TARGET_NEW_LEADS_PER_RUN" | tee -a workflow.log
          echo "Dry run: $DRY_RUN" | tee -a workflow.log
          echo "Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" | tee -a workflow.log
          echo "" | tee -a workflow.log
          
          # Ensure we have the API key
          if [ -z "$INSTANTLY_API_KEY" ]; then
            echo "‚ùå INSTANTLY_API_KEY not available in environment" | tee -a workflow.log
            exit 1
          fi
          
          echo "‚úÖ Environment variables validated" | tee -a workflow.log
          
          # Run the sync script with full output capture
          echo "üìù Running sync_once.py..." | tee -a workflow.log
          python sync_once.py 2>&1 | tee -a workflow.log || {
            exit_code=$?
            echo "‚ùå sync_once.py failed with exit code $exit_code" | tee -a workflow.log
            
            # If sync fails, try debug script
            echo "üîç Running debug script..." | tee -a workflow.log
            python debug_sync.py 2>&1 | tee -a workflow.log || echo "Debug script also failed" | tee -a workflow.log
            
            # List any log files created
            echo "üìÑ Log files in directory:" | tee -a workflow.log
            ls -la *.log 2>&1 | tee -a workflow.log || echo "No .log files found" | tee -a workflow.log
            
            exit $exit_code
          }
          
          # Dynamic footer message based on actual verification system status
          if python3 -c "from simple_async_verification import trigger_verification_for_new_leads; print('simple async available')" 2>/dev/null; then
            echo "‚úÖ Lead creation complete (simple async verification system active)" | tee -a workflow.log
          else
            echo "‚úÖ Lead creation complete (async verification system not available)" | tee -a workflow.log
          fi
      
      - name: Send logs to external service
        if: always()
        env:
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
          TARGET_NEW_LEADS_PER_RUN: ${{ github.event.inputs.target_leads || '100' }}
        run: |
          echo "üì§ Sending logs for remote analysis..."
          python send_logs.py || echo "‚ö†Ô∏è Log transmission failed, continuing..."
          
      - name: Cleanup credentials
        if: always()
        run: |
          rm -f config/secrets/bigquery-credentials.json
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-logs-${{ github.run_number }}
          path: |
            *.log
            workflow.log
          if-no-files-found: warn
          retention-days: 7